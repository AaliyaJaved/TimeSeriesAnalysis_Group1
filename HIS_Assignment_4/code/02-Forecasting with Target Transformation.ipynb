{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b25018c9-2624-434c-aa23-04be1d73e729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zain.hanif\\Desktop\\University\\HIS Project\\Modern-Time-Series-Forecasting-with-Python\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f023467-970a-461e-a60f-7a66fce6a497",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zain.hanif\\AppData\\Local\\Temp\\ipykernel_21584\\773209181.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.autonotebook import tqdm\n",
    "import warnings\n",
    "import humanize\n",
    "import joblib\n",
    "\n",
    "from darts.metrics import mase, mse, mae\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from src.utils.ts_utils import forecast_bias, darts_metrics_adapter\n",
    "from src.utils.general import LogTime\n",
    "from src.utils import plotting_utils\n",
    "from src.forecasting.ml_forecasting import MissingValueConfig, FeatureConfig, ModelConfig, MLForecast, calculate_metrics\n",
    "from IPython.display import display, HTML\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "np.random.seed(42)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41ae72a1-3721-4b36-b211-b78d4b09c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"imgs/chapter_7\", exist_ok=True)\n",
    "preprocessed = Path(\"C:/Users/zain.hanif/Desktop/University/HIS Project/Modern-Time-Series-Forecasting-with-Python/data/london_smart_meters/preprocessed\")\n",
    "output = Path(\"C:/Users/zain.hanif/Desktop/University/HIS Project/Modern-Time-Series-Forecasting-with-Python/data/london_smart_meters/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8900cd43-718f-4dc1-ace9-ef9dc99b600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_plot(fig, legends = None, xlabel=\"Time\", ylabel=\"Value\", title=\"\"):\n",
    "    if legends:\n",
    "        names = cycle(legends)\n",
    "        fig.for_each_trace(lambda t:  t.update(name = next(names)))\n",
    "    fig.update_layout(\n",
    "            autosize=False,\n",
    "            width=900,\n",
    "            height=500,\n",
    "            title_text=title,\n",
    "            title={\n",
    "            'x':0.5,\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top'},\n",
    "            titlefont={\n",
    "                \"size\": 20\n",
    "            },\n",
    "            legend_title = None,\n",
    "            yaxis=dict(\n",
    "                title_text=ylabel,\n",
    "                titlefont=dict(size=12),\n",
    "            ),\n",
    "            xaxis=dict(\n",
    "                title_text=xlabel,\n",
    "                titlefont=dict(size=12),\n",
    "            )\n",
    "        )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efe0e2b6-605d-423b-b75c-cb7b4e5d34e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_abs_min(s, props=''):\n",
    "    return np.where(s == np.nanmin(np.abs(s.values)), props, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10b5686a-c35c-4191-9185-365a30e09255",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #Readin the missing value imputed and train test split data\n",
    "    train_df = pd.read_parquet(preprocessed/\"selected_blocks_train_missing_imputed_feature_engg.parquet\")\n",
    "    auto_stat_target = pd.read_parquet(preprocessed/\"selected_blocks_train_auto_stat_target.parquet\")\n",
    "    transformer_pipelines = joblib.load(preprocessed/\"auto_transformer_pipelines_train.pkl\")\n",
    "    #Reading in validation as test\n",
    "    test_df = pd.read_parquet(preprocessed/\"selected_blocks_val_missing_imputed_feature_engg.parquet\")\n",
    "    # Joining the transformed target \n",
    "    train_df = train_df.set_index(['LCLid','timestamp']).join(auto_stat_target).reset_index()\n",
    "    # #Renaming energy\n",
    "    # test_df.rename(columns={\"energy_consumption\":\"energy_consumption_auto_stat\"}, inplace=True)\n",
    "except FileNotFoundError:\n",
    "    display(HTML(\"\"\"\n",
    "    <div class=\"alert alert-block alert-warning\">\n",
    "    <b>Warning!</b> File not found. Please make sure you have run 01-Feature Engineering.ipynb and 02-Dealing with Non-Stationarity.ipynb in Chapter06 and Chapter07\n",
    "    </div>\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6046a8fe-283d-4f4b-ab1f-a5b23bad55e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df.LCLid.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6eca727d-7eaa-4d01-8d8d-1726b1422b0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    baseline_metrics_df = pd.read_pickle(output/\"ml_single_step_metrics_val_df.pkl\")\n",
    "    baseline_aggregate_metrics_df = pd.read_pickle(output/\"ml_single_step_aggregate_metrics_val.pkl\")\n",
    "except FileNotFoundError:\n",
    "    display(HTML(\"\"\"\n",
    "    <div class=\"alert alert-block alert-warning\">\n",
    "    <b>Warning!</b> File not found. Please make sure you have run 01-Forecasting with ML.ipynb in Chapter08\n",
    "    </div>\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b79dcefd-d77c-4f89-ace5-eb10a670cb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LCLid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>energy_consumption</th>\n",
       "      <th>frequency</th>\n",
       "      <th>series_length</th>\n",
       "      <th>stdorToU</th>\n",
       "      <th>Acorn</th>\n",
       "      <th>Acorn_grouped</th>\n",
       "      <th>file</th>\n",
       "      <th>holidays</th>\n",
       "      <th>...</th>\n",
       "      <th>timestamp_Minute_sin_2</th>\n",
       "      <th>timestamp_Minute_sin_3</th>\n",
       "      <th>timestamp_Minute_sin_4</th>\n",
       "      <th>timestamp_Minute_sin_5</th>\n",
       "      <th>timestamp_Minute_cos_1</th>\n",
       "      <th>timestamp_Minute_cos_2</th>\n",
       "      <th>timestamp_Minute_cos_3</th>\n",
       "      <th>timestamp_Minute_cos_4</th>\n",
       "      <th>timestamp_Minute_cos_5</th>\n",
       "      <th>energy_consumption_auto_stat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAC000061</td>\n",
       "      <td>2012-01-01 00:00:00</td>\n",
       "      <td>0.114</td>\n",
       "      <td>30min</td>\n",
       "      <td>37872</td>\n",
       "      <td>Std</td>\n",
       "      <td>ACORN-Q</td>\n",
       "      <td>Adversity</td>\n",
       "      <td>block_96</td>\n",
       "      <td>NO_HOLIDAY</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.555465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAC000061</td>\n",
       "      <td>2012-01-01 00:30:00</td>\n",
       "      <td>0.113</td>\n",
       "      <td>30min</td>\n",
       "      <td>37872</td>\n",
       "      <td>Std</td>\n",
       "      <td>ACORN-Q</td>\n",
       "      <td>Adversity</td>\n",
       "      <td>block_96</td>\n",
       "      <td>NO_HOLIDAY</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.133108e-15</td>\n",
       "      <td>2.143751e-15</td>\n",
       "      <td>-2.266215e-15</td>\n",
       "      <td>6.123234e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.560217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAC000061</td>\n",
       "      <td>2012-01-01 01:00:00</td>\n",
       "      <td>0.113</td>\n",
       "      <td>30min</td>\n",
       "      <td>37872</td>\n",
       "      <td>Std</td>\n",
       "      <td>ACORN-Q</td>\n",
       "      <td>Adversity</td>\n",
       "      <td>block_96</td>\n",
       "      <td>NO_HOLIDAY</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.563023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAC000061</td>\n",
       "      <td>2012-01-01 01:30:00</td>\n",
       "      <td>0.098</td>\n",
       "      <td>30min</td>\n",
       "      <td>37872</td>\n",
       "      <td>Std</td>\n",
       "      <td>ACORN-Q</td>\n",
       "      <td>Adversity</td>\n",
       "      <td>block_96</td>\n",
       "      <td>NO_HOLIDAY</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.133108e-15</td>\n",
       "      <td>2.143751e-15</td>\n",
       "      <td>-2.266215e-15</td>\n",
       "      <td>6.123234e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.560639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAC000061</td>\n",
       "      <td>2012-01-01 02:00:00</td>\n",
       "      <td>0.060</td>\n",
       "      <td>30min</td>\n",
       "      <td>37872</td>\n",
       "      <td>Std</td>\n",
       "      <td>ACORN-Q</td>\n",
       "      <td>Adversity</td>\n",
       "      <td>block_96</td>\n",
       "      <td>NO_HOLIDAY</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.553762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LCLid           timestamp  energy_consumption frequency  series_length  \\\n",
       "0  MAC000061 2012-01-01 00:00:00               0.114     30min          37872   \n",
       "1  MAC000061 2012-01-01 00:30:00               0.113     30min          37872   \n",
       "2  MAC000061 2012-01-01 01:00:00               0.113     30min          37872   \n",
       "3  MAC000061 2012-01-01 01:30:00               0.098     30min          37872   \n",
       "4  MAC000061 2012-01-01 02:00:00               0.060     30min          37872   \n",
       "\n",
       "  stdorToU    Acorn Acorn_grouped      file    holidays  ...  \\\n",
       "0      Std  ACORN-Q     Adversity  block_96  NO_HOLIDAY  ...   \n",
       "1      Std  ACORN-Q     Adversity  block_96  NO_HOLIDAY  ...   \n",
       "2      Std  ACORN-Q     Adversity  block_96  NO_HOLIDAY  ...   \n",
       "3      Std  ACORN-Q     Adversity  block_96  NO_HOLIDAY  ...   \n",
       "4      Std  ACORN-Q     Adversity  block_96  NO_HOLIDAY  ...   \n",
       "\n",
       "   timestamp_Minute_sin_2  timestamp_Minute_sin_3  timestamp_Minute_sin_4  \\\n",
       "0            0.000000e+00            0.000000e+00            0.000000e+00   \n",
       "1           -1.133108e-15            2.143751e-15           -2.266215e-15   \n",
       "2            0.000000e+00            0.000000e+00            0.000000e+00   \n",
       "3           -1.133108e-15            2.143751e-15           -2.266215e-15   \n",
       "4            0.000000e+00            0.000000e+00            0.000000e+00   \n",
       "\n",
       "   timestamp_Minute_sin_5  timestamp_Minute_cos_1  timestamp_Minute_cos_2  \\\n",
       "0            0.000000e+00                     1.0                     1.0   \n",
       "1            6.123234e-16                    -1.0                     1.0   \n",
       "2            0.000000e+00                     1.0                     1.0   \n",
       "3            6.123234e-16                    -1.0                     1.0   \n",
       "4            0.000000e+00                     1.0                     1.0   \n",
       "\n",
       "   timestamp_Minute_cos_3 timestamp_Minute_cos_4 timestamp_Minute_cos_5  \\\n",
       "0                     1.0                    1.0                    1.0   \n",
       "1                    -1.0                    1.0                   -1.0   \n",
       "2                     1.0                    1.0                    1.0   \n",
       "3                    -1.0                    1.0                   -1.0   \n",
       "4                     1.0                    1.0                    1.0   \n",
       "\n",
       "   energy_consumption_auto_stat  \n",
       "0                      0.555465  \n",
       "1                      0.560217  \n",
       "2                      0.563023  \n",
       "3                      0.560639  \n",
       "4                      0.553762  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debe3f31-9081-49ee-beed-b56c040cebc2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Feature Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d230f461-5a87-4955-8c98-a29f7fbba75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_config = FeatureConfig(\n",
    "    date=\"timestamp\",\n",
    "    target=\"energy_consumption_auto_stat\",\n",
    "    original_target=\"energy_consumption\",\n",
    "    continuous_features=[\n",
    "        \"visibility\",\n",
    "        \"windBearing\",\n",
    "        \"temperature\",\n",
    "        \"dewPoint\",\n",
    "        \"pressure\",\n",
    "        \"apparentTemperature\",\n",
    "        \"windSpeed\",\n",
    "        \"humidity\",\n",
    "        \"energy_consumption_lag_1\",\n",
    "        \"energy_consumption_lag_2\",\n",
    "        \"energy_consumption_lag_3\",\n",
    "        \"energy_consumption_lag_4\",\n",
    "        \"energy_consumption_lag_5\",\n",
    "        \"energy_consumption_lag_46\",\n",
    "        \"energy_consumption_lag_47\",\n",
    "        \"energy_consumption_lag_48\",\n",
    "        \"energy_consumption_lag_49\",\n",
    "        \"energy_consumption_lag_50\",\n",
    "        \"energy_consumption_lag_334\",\n",
    "        \"energy_consumption_lag_335\",\n",
    "        \"energy_consumption_lag_336\",\n",
    "        \"energy_consumption_lag_337\",\n",
    "        \"energy_consumption_lag_338\",\n",
    "        \"energy_consumption_rolling_3_mean\",\n",
    "        \"energy_consumption_rolling_3_std\",\n",
    "        \"energy_consumption_rolling_6_mean\",\n",
    "        \"energy_consumption_rolling_6_std\",\n",
    "        \"energy_consumption_rolling_12_mean\",\n",
    "        \"energy_consumption_rolling_12_std\",\n",
    "        \"energy_consumption_rolling_48_mean\",\n",
    "        \"energy_consumption_rolling_48_std\",\n",
    "        \"energy_consumption_48_seasonal_rolling_3_mean\",\n",
    "        \"energy_consumption_48_seasonal_rolling_3_std\",\n",
    "        \"energy_consumption_336_seasonal_rolling_3_mean\",\n",
    "        \"energy_consumption_336_seasonal_rolling_3_std\",\n",
    "        \"energy_consumption_ewma_span_2880\",\n",
    "        \"energy_consumption_ewma_span_336\",\n",
    "        \"energy_consumption_ewma_span_48\",\n",
    "        \"timestamp_Elapsed\",\n",
    "        \"timestamp_Month_sin_1\",\n",
    "        \"timestamp_Month_sin_2\",\n",
    "        \"timestamp_Month_sin_3\",\n",
    "        \"timestamp_Month_sin_4\",\n",
    "        \"timestamp_Month_sin_5\",\n",
    "        \"timestamp_Month_cos_1\",\n",
    "        \"timestamp_Month_cos_2\",\n",
    "        \"timestamp_Month_cos_3\",\n",
    "        \"timestamp_Month_cos_4\",\n",
    "        \"timestamp_Month_cos_5\",\n",
    "        \"timestamp_Hour_sin_1\",\n",
    "        \"timestamp_Hour_sin_2\",\n",
    "        \"timestamp_Hour_sin_3\",\n",
    "        \"timestamp_Hour_sin_4\",\n",
    "        \"timestamp_Hour_sin_5\",\n",
    "        \"timestamp_Hour_cos_1\",\n",
    "        \"timestamp_Hour_cos_2\",\n",
    "        \"timestamp_Hour_cos_3\",\n",
    "        \"timestamp_Hour_cos_4\",\n",
    "        \"timestamp_Hour_cos_5\",\n",
    "        \"timestamp_Minute_sin_1\",\n",
    "        \"timestamp_Minute_sin_2\",\n",
    "        \"timestamp_Minute_sin_3\",\n",
    "        \"timestamp_Minute_sin_4\",\n",
    "        \"timestamp_Minute_sin_5\",\n",
    "        \"timestamp_Minute_cos_1\",\n",
    "        \"timestamp_Minute_cos_2\",\n",
    "        \"timestamp_Minute_cos_3\",\n",
    "        \"timestamp_Minute_cos_4\",\n",
    "        \"timestamp_Minute_cos_5\",\n",
    "    ],\n",
    "    categorical_features=[\n",
    "        \"holidays\",\n",
    "        \"precipType\",\n",
    "        \"icon\",\n",
    "        \"summary\",\n",
    "        \"timestamp_Month\",\n",
    "        \"timestamp_Quarter\",\n",
    "        \"timestamp_WeekDay\",\n",
    "        \"timestamp_Dayofweek\",\n",
    "        \"timestamp_Dayofyear\",\n",
    "        \"timestamp_Hour\",\n",
    "        \"timestamp_Minute\",\n",
    "    ],\n",
    "    boolean_features=[\n",
    "        \"timestamp_Is_quarter_end\",\n",
    "        \"timestamp_Is_quarter_start\",\n",
    "        \"timestamp_Is_year_end\",\n",
    "        \"timestamp_Is_year_start\",\n",
    "        \"timestamp_Is_month_start\",\n",
    "    ],\n",
    "    index_cols=[\"timestamp\"],\n",
    "    exogenous_features=[\n",
    "        \"holidays\",\n",
    "        \"precipType\",\n",
    "        \"icon\",\n",
    "        \"summary\",\n",
    "        \"visibility\",\n",
    "        \"windBearing\",\n",
    "        \"temperature\",\n",
    "        \"dewPoint\",\n",
    "        \"pressure\",\n",
    "        \"apparentTemperature\",\n",
    "        \"windSpeed\",\n",
    "        \"humidity\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcc8075-486a-42ab-9ec8-ddd06355dd93",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Missing Value Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4377661a-4b94-41cd-a599-7636907eeba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value_config = MissingValueConfig(\n",
    "    bfill_columns=[\n",
    "        \"energy_consumption_lag_1\",\n",
    "        \"energy_consumption_lag_2\",\n",
    "        \"energy_consumption_lag_3\",\n",
    "        \"energy_consumption_lag_4\",\n",
    "        \"energy_consumption_lag_5\",\n",
    "        \"energy_consumption_lag_46\",\n",
    "        \"energy_consumption_lag_47\",\n",
    "        \"energy_consumption_lag_48\",\n",
    "        \"energy_consumption_lag_49\",\n",
    "        \"energy_consumption_lag_50\",\n",
    "        \"energy_consumption_lag_334\",\n",
    "        \"energy_consumption_lag_335\",\n",
    "        \"energy_consumption_lag_336\",\n",
    "        \"energy_consumption_lag_337\",\n",
    "        \"energy_consumption_lag_338\",\n",
    "        \"energy_consumption_rolling_3_mean\",\n",
    "        \"energy_consumption_rolling_3_std\",\n",
    "        \"energy_consumption_rolling_6_mean\",\n",
    "        \"energy_consumption_rolling_6_std\",\n",
    "        \"energy_consumption_rolling_12_mean\",\n",
    "        \"energy_consumption_rolling_12_std\",\n",
    "        \"energy_consumption_rolling_48_mean\",\n",
    "        \"energy_consumption_rolling_48_std\",\n",
    "        \"energy_consumption_48_seasonal_rolling_3_mean\",\n",
    "        \"energy_consumption_48_seasonal_rolling_3_std\",\n",
    "        \"energy_consumption_336_seasonal_rolling_3_mean\",\n",
    "        \"energy_consumption_336_seasonal_rolling_3_std\",\n",
    "        \"energy_consumption_ewma__span_2880\",\n",
    "        \"energy_consumption_ewma__span_336\",\n",
    "        \"energy_consumption_ewma__span_48\",\n",
    "    ],\n",
    "    ffill_columns=[],\n",
    "    zero_fill_columns=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783e372f-6459-49cc-b2d1-640c6b2b5401",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Running ML Forecast for all consumers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c24cf01-6f27-41a9-a065-14b2229c98c4",
   "metadata": {},
   "source": [
    "Running Lasso Regression, XGB Random Forest, and LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d213e79-ff52-4476-be9f-a878da9bf9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_config, feature_config, missing_config, target_transformer, train_features, train_target, test_features, test_target, train_target_original=None):\n",
    "    ml_model = MLForecast(model_config=model_config, feature_config=feat_config, missing_config=missing_value_config, target_transformer=target_transformer)\n",
    "    ml_model.fit(train_features, train_target, is_transformed=True)\n",
    "    y_pred = ml_model.predict(test_features)\n",
    "    feat_df = ml_model.feature_importance()\n",
    "    metrics = calculate_metrics(test_target, y_pred, model_config.name, train_target_original)\n",
    "    return y_pred, metrics, feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51eb3210-9577-4065-889a-55cf12931f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from xgboost import XGBRFRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "366fe44b-bbb7-46e0-a898-2b9b5e0bba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcl_ids = sorted(train_df.LCLid.unique())\n",
    "models_to_run = [\n",
    "    ModelConfig(model = LassoCV(), name=\"Lasso Regression\", normalize=True, fill_missing=True),\n",
    "    ModelConfig(model = XGBRFRegressor(random_state=42, max_depth=4), name=\"XGB Random Forest\", normalize=False, fill_missing=False),\n",
    "    ModelConfig(model = LGBMRegressor(random_state=42), name=\"LightGBM\", normalize=False, fill_missing=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb50d352-fb06-47d8-b54a-a32d26034120",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a3d17913f74201bd4f5816e1723bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 35088, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.549685\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 35088, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.573847\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 35088, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -0.000004\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 35088, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.621877\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 35088, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.532837\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 35088, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.572746\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009365 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 35088, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.548048\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 35088, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.572730\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 35088, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.623420\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 35088, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.564119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 35088, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.631138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 35088, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.000004\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008004 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 32112, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -0.000022\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 31920, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.971043\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 30144, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.562939\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 30144, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.526509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 30096, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.619637\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 30048, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.565045\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 29856, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.557443\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 29808, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.590021\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 29760, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.558292\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007004 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 29760, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 29760, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.607783\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007008 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 29520, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.540530\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 29424, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.622449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 29424, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.551266\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 29424, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.565261\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 29424, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.585869\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 29232, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.526332\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 29232, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.579554\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 29184, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.639040\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 29184, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.526277\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8070\n",
      "[LightGBM] [Info] Number of data points in the train set: 28848, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.515246\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 28608, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.575962\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006099 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 28608, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.561316\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 28608, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.672198\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7770\n",
      "[LightGBM] [Info] Number of data points in the train set: 28608, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -0.000001\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 28608, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.587089\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 28464, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.596716\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 28416, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.597667\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 28272, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.578746\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 28224, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.599999\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 28224, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.577271\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006022 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 28224, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.566450\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 28080, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.556328\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009058 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 28032, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.581785\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 27888, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.622815\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 27744, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.562455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 27504, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.586643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 27504, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.587291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 27456, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.535395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 27408, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 1.924435\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005793 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 27360, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.549799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005812 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 27360, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.615394\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 27264, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.510827\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 27216, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.576101\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 27216, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.587129\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 27024, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.000014\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 26976, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.618479\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005884 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 26880, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.611086\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004902 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 26688, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.000048\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005999 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 26400, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.096676\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 26352, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.539094\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005999 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 29712, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.592298\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 29712, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.583106\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.539205\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001413 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 29568, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.739394\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 29424, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.530247\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 29232, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 1.034012\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 29280, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.000002\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005994 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 29232, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.556078\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.582614\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.599769\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005758 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.577128\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 29088, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.564290\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 28896, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.545689\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 26784, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.583896\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 28848, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.559469\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 28800, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -0.000008\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006993 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 26256, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.556498\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 26112, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.000002\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 26208, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.542697\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 26160, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.614402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6795\n",
      "[LightGBM] [Info] Number of data points in the train set: 28464, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.512353\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 28560, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 28512, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.622601\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 25680, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.614878\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 22560, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.597181\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 22224, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.619196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 22224, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.606840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 22080, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.595108\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005837 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 22032, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.597977\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 21888, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.556007\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 21840, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.617237\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 21840, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.591601\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 21840, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.578398\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 18288, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 21744, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -0.000020\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 21552, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.632441\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 21552, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.569954\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 21552, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.562417\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 21408, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.555575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7804\n",
      "[LightGBM] [Info] Number of data points in the train set: 21360, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.517975\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 21360, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.600620\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 21168, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.633604\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002604 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 21072, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.591772\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 20976, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.621925\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 20832, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.646320\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 20688, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.629189\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 26064, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.627178\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 28368, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.555159\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 28368, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.574290\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 28272, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.549166\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006862 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 28128, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.595958\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004786 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 31536, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.544589\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 31488, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.143582\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 31296, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -0.000017\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 31296, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.727479\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007922 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 35088, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.623573\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 35088, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.583620\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 35088, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.622058\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001850 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 35088, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.633053\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 35088, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.533477\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 25776, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.546740\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 25776, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.000001\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 25776, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -0.000039\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 25728, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.601044\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 30528, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.562403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 30480, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.548371\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 30480, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -0.000027\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8115\n",
      "[LightGBM] [Info] Number of data points in the train set: 35088, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 0.575251\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "all_metrics = []\n",
    "#We can parallelize this loop to run this faster\n",
    "for lcl_id in tqdm(lcl_ids):\n",
    "    for model_config in models_to_run:\n",
    "        model_config = model_config.clone()\n",
    "        X_train, y_train, y_train_orig = feat_config.get_X_y(train_df.loc[train_df.LCLid==lcl_id,:], categorical=False, exogenous=False)\n",
    "        X_test, _, y_test_orig = feat_config.get_X_y(test_df.loc[test_df.LCLid==lcl_id,:], categorical=False, exogenous=False)\n",
    "        transformer = transformer_pipelines[lcl_id]\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            y_pred, metrics, feat_df = evaluate_model(model_config, feat_config, missing_value_config, transformer, X_train, y_train, X_test, y_test_orig, y_train_orig)\n",
    "        y_pred.name = \"predictions\"\n",
    "        y_pred = y_pred.to_frame()\n",
    "        y_pred['LCLid'] = lcl_id\n",
    "        y_pred['Algorithm'] = model_config.name + \"_auto_stat\"\n",
    "        metrics[\"LCLid\"] = lcl_id\n",
    "        metrics[\"Algorithm\"] = model_config.name + \"_auto_stat\"\n",
    "        y_pred['energy_consumption'] = y_test_orig.values\n",
    "        all_preds.append(y_pred)\n",
    "        all_metrics.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef397c8-d658-48e7-91e1-224319042e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.concat(all_preds)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be827e9e-a406-4ee8-8fd8-9923f1c8bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e51169-e983-44f0-97b0-c39d988ce549",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluation of ML Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e288dfc0-63a6-422e-8dde-a436bacb22cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import ts_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cab8d2-3a10-4eff-a580-4a849f2eb44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_aggregate_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64157814-0544-485a-bdcc-d97f4ae9e0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = baseline_aggregate_metrics_df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca44213-d681-4d4d-bd23-fcd4e32e491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for model in models_to_run:\n",
    "    pred_mask = pred_df.Algorithm==model.name+\"_auto_stat\"\n",
    "    metric_mask = metrics_df.Algorithm==model.name+\"_auto_stat\"\n",
    "    metrics.append({\n",
    "    \"Algorithm\": model.name+\"_auto_stat\",\n",
    "    \"MAE\": ts_utils.mae(pred_df.loc[pred_mask,\"energy_consumption\"], pred_df.loc[pred_mask,\"predictions\"]),\n",
    "    \"MSE\": ts_utils.mse(pred_df.loc[pred_mask,\"energy_consumption\"], pred_df.loc[pred_mask,\"predictions\"]),\n",
    "    \"meanMASE\": metrics_df.loc[metric_mask, \"MASE\"].mean(),\n",
    "    \"Forecast Bias\": ts_utils.forecast_bias_aggregate(pred_df.loc[pred_mask,\"energy_consumption\"], pred_df.loc[pred_mask,\"predictions\"])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08744668-4986-43f1-b744-fd5ad49353c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_metrics_df = pd.DataFrame(metrics)\n",
    "agg_metrics_df.style.format({\"MAE\": \"{:.3f}\", \n",
    "                          \"MSE\": \"{:.3f}\", \n",
    "                          \"meanMASE\": \"{:.3f}\", \n",
    "                          \"Forecast Bias\": \"{:.2f}%\"}).highlight_min(color='lightgreen', subset=[\"MAE\",\"MSE\",\"meanMASE\"]).apply(highlight_abs_min, props='color:black;background-color:lightgreen', axis=0, subset=['Forecast Bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d164184-dca3-4472-a138-c260019eeb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(metrics_df, \n",
    "                   x=\"MASE\", \n",
    "                   color=\"Algorithm\",\n",
    "                   pattern_shape=\"Algorithm\", \n",
    "                   marginal=\"box\", \n",
    "                   nbins=500, \n",
    "                   barmode=\"overlay\",\n",
    "                   histnorm=\"probability density\")\n",
    "fig = format_plot(fig, xlabel=\"MASE\", ylabel=\"Probability Density\", title=\"Distribution of MASE in the dataset\")\n",
    "fig.update_layout(xaxis_range=[0,2.5])\n",
    "# fig.write_image(\"imgs/chapter_7/mase_dist.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05599872-81eb-406c-b096-cece0d153817",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(metrics_df, \n",
    "                   x=\"MAE\", \n",
    "                   color=\"Algorithm\",\n",
    "                   pattern_shape=\"Algorithm\", \n",
    "                   marginal=\"box\", \n",
    "                   nbins=100, \n",
    "                   barmode=\"overlay\",\n",
    "                   histnorm=\"probability density\")\n",
    "fig = format_plot(fig, xlabel=\"MAE\", ylabel=\"Probability Density\", title=\"Distribution of MAE in the dataset\")\n",
    "# fig.write_image(\"imgs/chapter_7/mae_dist.png\")\n",
    "fig.update_layout(xaxis_range=[0,0.4])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e89266e-ab40-4f44-9461-ec0c755c6a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(metrics_df, \n",
    "                   x=\"MSE\", \n",
    "                   color=\"Algorithm\",\n",
    "                   pattern_shape=\"Algorithm\", \n",
    "                   marginal=\"box\", \n",
    "                   nbins=500, \n",
    "                   barmode=\"overlay\",\n",
    "                   histnorm=\"probability density\")\n",
    "fig = format_plot(fig, xlabel=\"MSE\", ylabel=\"Probability Density\", title=\"Distribution of MSE in the dataset\")\n",
    "fig.update_layout(xaxis_range=[0,0.3])\n",
    "# fig.write_image(\"imgs/chapter_7/mse_dist.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2695707d-1e83-4289-9aea-859bbf83586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(metrics_df, \n",
    "                   x=\"Forecast Bias\", \n",
    "                   color=\"Algorithm\",\n",
    "                   pattern_shape=\"Algorithm\", \n",
    "                   marginal=\"box\", \n",
    "                   nbins=250,\n",
    "                   barmode=\"overlay\",\n",
    "                   histnorm=\"probability density\")\n",
    "fig = format_plot(fig, xlabel=\"Forecast Bias\", ylabel=\"Probability Density\", title=\"Distribution of Forecast Bias in the dataset\")\n",
    "fig.update_layout(xaxis_range=[-50,30])\n",
    "# fig.write_image(\"imgs/chapter_7/bias_dist.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8563e46a-8c50-4ae4-8321-2a36e9d104d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Saving the Baseline Forecasts and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330d2005-faba-44da-89a9-29b088758998",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"C:/Users/zain.hanif/Desktop/University/HIS Project/Modern-Time-Series-Forecasting-with-Python/data/london_smart_meters/output\", exist_ok=True)\n",
    "output = Path(\"C:/Users/zain.hanif/Desktop/University/HIS Project/Modern-Time-Series-Forecasting-with-Python/data/london_smart_meters/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f475ae-2f2e-4ca4-9941-98ae14d764b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_pickle(output/\"ml_single_step_prediction_auto_stationary_val_df.pkl\")\n",
    "metrics_df.to_pickle(output/\"ml_single_step_metrics_auto_stationary_val_df.pkl\")\n",
    "agg_metrics_df.to_pickle(output/\"ml_single_step_aggregate_metrics_auto_stationary_val.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66c5424-cd2c-4687-8e83-946ff1628306",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
